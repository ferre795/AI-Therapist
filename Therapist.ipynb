{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhAFjMODTe0L"
      },
      "outputs": [],
      "source": [
        "!pip install -U datasets huggingface_hub fsspec\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XRzOi33XoC5"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"dair-ai/emotion\")\n",
        "print(dataset['train'][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PyqVBN_YGhp"
      },
      "outputs": [],
      "source": [
        "label_names = dataset[\"train\"].features[\"label\"].names\n",
        "label_mapping = {i: label for i, label in enumerate(label_names)}\n",
        "label_mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0DgiJeZpS69"
      },
      "outputs": [],
      "source": [
        "train_text = dataset['train']['text']\n",
        "train_labels = dataset['train']['label']\n",
        "\n",
        "val_text = dataset['validation']['text']\n",
        "val_labels = dataset['validation']['label']\n",
        "\n",
        "test_text = dataset['test']['text']\n",
        "test_labels = dataset['test']['label']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FZytdK2qwOh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-w2djg4q0oB"
      },
      "outputs": [],
      "source": [
        "vocab_size = 20000\n",
        "max_length = 100\n",
        "trunc_type='post'\n",
        "padding_type='post'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5G3I9dgsqm5n"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(train_text)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(train_text)\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "val_sequences = tokenizer.texts_to_sequences(val_text)\n",
        "val_padded = pad_sequences(val_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(test_text)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKFlQSx9rD6Y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "train_padded = np.array(training_padded)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "val_padded = np.array(val_padded)\n",
        "val_labels = np.array(val_labels)\n",
        "\n",
        "test_padded = np.array(testing_padded)\n",
        "test_labels = np.array(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5XBkgNwr-Ix"
      },
      "outputs": [],
      "source": [
        "class EmotionClassifier(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout_rate, output_dim):\n",
        "    super().__init__()\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.pooling = tf.keras.layers.GlobalAveragePooling1D()\n",
        "    self.layer1 = tf.keras.layers.Dense(hidden_dim, activation = 'relu')\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "    self.output_layer = tf.keras.layers.Dense(output_dim, activation = 'softmax')\n",
        "\n",
        "  def call(self, x, training=False):\n",
        "    x = self.embedding(x)\n",
        "    x = self.pooling(x)\n",
        "    x = self.layer1(x)\n",
        "    x = self.dropout(x, training=training)\n",
        "    return self.output_layer(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9CsvsunrWxY"
      },
      "outputs": [],
      "source": [
        "model = EmotionClassifier(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=128,\n",
        "    hidden_dim=32,\n",
        "    dropout_rate = 0.3,\n",
        "    output_dim=len(label_mapping)\n",
        ")\n",
        "\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='loss',\n",
        "    patience=2,\n",
        "    min_delta=0.001,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "history = model.fit(train_padded, train_labels, epochs=40, validation_data=(val_padded, val_labels), callbacks = [callback], verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2UME8HZxSGi"
      },
      "outputs": [],
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_padded, test_labels, verbose=2)\n",
        "\n",
        "print(f\"\\n Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\" Test Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ygGgtKK2F3O"
      },
      "outputs": [],
      "source": [
        "model.save(\"emotion_classifier.h5\")\n",
        "with open(\"tokenizer.json\", \"w\") as f:\n",
        "    f.write(tokenizer.to_json())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMaTAOvr6bDE"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "model_GPT = AutoModelForCausalLM.from_pretrained(model_id).to(\"cuda\")\n",
        "tokenizer_GPT = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "tokenizer_GPT.pad_token = tokenizer_GPT.eos_token\n",
        "\n",
        "!pip install transformers datasets peft accelerate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extra_df = pd.read_csv(\"/content/therapist_prompts_100_total.csv\")\n",
        "extra_df.head()\n",
        "\n",
        "prompts = []\n",
        "therapist = []\n",
        "\n",
        "for index, row in extra_df.iterrows():\n",
        "  prompts.append(row['prompt'])\n",
        "  therapist.append(row['response'])\n"
      ],
      "metadata": {
        "id": "NLT1B-PkK1SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlah45aZclYB"
      },
      "outputs": [],
      "source": [
        "label_map = {0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear', 5: 'surprise'}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wHfyEB698CR"
      },
      "outputs": [],
      "source": [
        "def get_emotion(text):\n",
        "  if not isinstance(text, str):\n",
        "    return None\n",
        "\n",
        "  seq = tokenizer.texts_to_sequences([text])\n",
        "  padded = pad_sequences(seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "  pred = model.predict(padded)\n",
        "  label = label_map[pred.argmax()]\n",
        "  return label\n",
        "\n",
        "formatted_data = []\n",
        "\n",
        "for q, r, e in zip(questions, responses, emotions):\n",
        "  prompt = f\"User feels {e}. They said {q}\\nTherapist: \"\n",
        "  formatted_data.append({\"prompt\": prompt, \"response\": r})\n",
        "\n",
        "extra_df.columns = extra_df.columns.str.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJjOv8RMQN_9"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "from peft import get_peft_model, LoraConfig, TaskType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7axNBexQQ0t"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "\n",
        "LoRA_data = []\n",
        "\n",
        "for p, t in zip(prompts, therapist):\n",
        "    LoRA_data.append({\"prompt\": p, \"response\": t})  # fixed variable names\n",
        "\n",
        "dataset = Dataset.from_list(LoRA_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvbyC5FtQVQO"
      },
      "outputs": [],
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"]\n",
        ")\n",
        "\n",
        "model_GPT = get_peft_model(model_GPT, lora_config)\n",
        "model_GPT.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4y2qN4qQ3Uc"
      },
      "outputs": [],
      "source": [
        "def tokenize(example):\n",
        "    full_text = example[\"prompt\"] + example[\"response\"]\n",
        "    tokens = tokenizer_GPT(\n",
        "        full_text,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=256\n",
        "    )\n",
        "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n",
        "    return tokens\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"prompt\", \"response\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ip78-Vu9Q7px"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./lora_therapist_model\",\n",
        "    per_device_train_batch_size=4,\n",
        "    num_train_epochs=5,\n",
        "    logging_steps=5,\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=1e-4,\n",
        "    fp16=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer_GPT,\n",
        "    mlm=False\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model_GPT,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pb6Z5SyVRDGF"
      },
      "outputs": [],
      "source": [
        "def generate_response(user_input):\n",
        "    emotion = get_emotion(user_input)\n",
        "    prompt = f\"User (feeling {emotion}): {user_input}\\nTherapist:\"\n",
        "\n",
        "    inputs = tokenizer_GPT(prompt, return_tensors=\"pt\", return_attention_mask=True).to(model_GPT.device)\n",
        "\n",
        "    output = model_GPT.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=90,\n",
        "        do_sample=True,\n",
        "        top_p=0.9,\n",
        "        temperature=0.8,\n",
        "        pad_token_id=tokenizer_GPT.eos_token_id,\n",
        "        eos_token_id=tokenizer_GPT.eos_token_id,\n",
        "        repetition_penalty=1.2\n",
        "    )\n",
        "\n",
        "    return tokenizer_GPT.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "response = generate_response(\"I feel completely lost and scared.\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1v5PxjaJRJsJ"
      },
      "outputs": [],
      "source": [
        "model_GPT.save_pretrained(\"./lora_therapist_adapters\")\n",
        "tokenizer_GPT.save_pretrained(\"./lora_therapist_adapters\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUcZhc5QZXoe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
